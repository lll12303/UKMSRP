{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.stats.multitest import multipletests"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_PATH = \"your_data.csv\"          # Input data file\n",
    "TIME_COL = \"time\"             # Follow-up time column\n",
    "EVENT_COL = \"status\"          # Event indicator (0/1)\n",
    "EXCLUDE_COLS = [\"Participant.ID\"]\n",
    "\n",
    "MIN_SAMPLES = 100             # Minimum samples per feature\n",
    "PENALIZER = 0.1               # L2 regularization strength\n",
    "CHUNK_SIZE = 100              # Number of features per batch\n",
    "N_JOBS = max(os.cpu_count() - 2, 1)\n",
    "\n",
    "OUTPUT_FULL = \"cox_results_full_with_fdr.csv\"\n",
    "OUTPUT_SIG = \"cox_results_significant.csv\""
   ],
   "id": "e587f0598c1a7f1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def standardize(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Z-score standardization.\"\"\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "\n",
    "def run_single_cox(df: pd.DataFrame, feature: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fit a univariate Cox model for a single feature.\n",
    "\n",
    "    Returns a dictionary of results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = df[[TIME_COL, EVENT_COL, feature]].dropna()\n",
    "\n",
    "        if len(data) < MIN_SAMPLES:\n",
    "            raise ValueError(f\"Insufficient samples (n={len(data)})\")\n",
    "\n",
    "        data[feature] = standardize(data[feature])\n",
    "\n",
    "        cph = CoxPHFitter(penalizer=PENALIZER)\n",
    "        cph.fit(data, duration_col=TIME_COL, event_col=EVENT_COL)\n",
    "\n",
    "        hr = cph.hazard_ratios_[feature]\n",
    "        ci_lower, ci_upper = np.exp(cph.confidence_intervals_.loc[feature])\n",
    "        p_value = cph.summary.loc[feature, \"p\"]\n",
    "\n",
    "        return {\n",
    "            \"feature\": feature,\n",
    "            \"HR\": hr,\n",
    "            \"CI_lower\": ci_lower,\n",
    "            \"CI_upper\": ci_upper,\n",
    "            \"p_value\": p_value,\n",
    "            \"n_samples\": len(data),\n",
    "            \"-log10(p)\": -np.log10(p_value)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"feature\": feature,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "def process_feature_chunk(df: pd.DataFrame, features: list) -> list:\n",
    "    \"\"\"Process a chunk of features.\"\"\"\n",
    "    return [run_single_cox(df, feature) for feature in features]"
   ],
   "id": "f067fc51358d1113",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def large_scale_cox(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run univariate Cox regression for all eligible features.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Identify candidate features\n",
    "    features = [\n",
    "        col for col in df.columns\n",
    "        if col not in [TIME_COL, EVENT_COL] + EXCLUDE_COLS\n",
    "    ]\n",
    "\n",
    "    print(f\"Total features to analyze: {len(features)}\")\n",
    "\n",
    "    # Split into chunks\n",
    "    feature_chunks = [\n",
    "        features[i:i + CHUNK_SIZE]\n",
    "        for i in range(0, len(features), CHUNK_SIZE)\n",
    "    ]\n",
    "\n",
    "    # Parallel execution\n",
    "    results_nested = Parallel(n_jobs=N_JOBS, verbose=10)(\n",
    "        delayed(process_feature_chunk)(df, chunk)\n",
    "        for chunk in feature_chunks\n",
    "    )\n",
    "\n",
    "    # Flatten results\n",
    "    results = [\n",
    "        r for chunk in results_nested for r in chunk\n",
    "        if \"error\" not in r\n",
    "    ]\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # FDR correction\n",
    "    _, fdr, _, _ = multipletests(\n",
    "        results_df[\"p_value\"].values,\n",
    "        method=\"fdr_bh\"\n",
    "    )\n",
    "    results_df[\"FDR\"] = fdr\n",
    "\n",
    "    # Significance labels\n",
    "    results_df[\"significance\"] = np.where(\n",
    "        results_df[\"FDR\"] < 0.05, \"**\",\n",
    "        np.where(results_df[\"p_value\"] < 0.05, \"*\", \"\")\n",
    "    )\n",
    "\n",
    "    elapsed = (time.time() - start_time) / 3600\n",
    "    print(f\"Analysis completed in {elapsed:.2f} hours\")\n",
    "\n",
    "    return results_df.sort_values(\"p_value\")\n"
   ],
   "id": "98d969b401306c92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "    # Drop unnecessary columns if present\n",
    "    df = df.drop(columns=[c for c in [\"Participant ID\"] if c in df.columns])\n",
    "\n",
    "    # Run Cox analysis\n",
    "    cox_results = large_scale_cox(df)\n",
    "\n",
    "    # Save full results\n",
    "    cox_results.to_csv(OUTPUT_FULL, index=False)\n",
    "\n",
    "    # Extract significant results\n",
    "    significant = cox_results[cox_results[\"FDR\"] < 0.05]\n",
    "    significant.to_csv(OUTPUT_SIG, index=False)\n",
    "\n",
    "    print(\"Top 20 significant features:\")\n",
    "    print(\n",
    "        significant[\n",
    "            [\"feature\", \"HR\", \"CI_lower\", \"CI_upper\", \"p_value\", \"FDR\"]\n",
    "        ].head(20)\n",
    "    )"
   ],
   "id": "de39a92743af440a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
