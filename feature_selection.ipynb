{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import squareform\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import scipy.stats\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_path = \"your_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "id_col = \"Participant ID\"\n",
    "label_col = \"status\"\n",
    "group_col = \"group\"\n",
    "feature_cols = [c for c in df.columns if c not in [id_col, label_col, group_col]]\n",
    "df_train = df[df[group_col] == \"train\"]\n",
    "df_test = df[df[group_col] == \"test\"]       # internal validation\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[label_col].copy()\n",
    "X_train = df_train[feature_cols].copy()\n",
    "y_train = df_train[label_col].copy()\n",
    "X_test = df_test[feature_cols].copy()\n",
    "y_test = df_test[label_col].copy()\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(\"Number of features:\", len(feature_cols))"
   ],
   "id": "fa999df1bfe9f891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlation_matrix = X.corr(method='spearman')\n",
    "# correlation_matrix.to_csv(\"correlation_matrix.csv\")\n",
    "\n",
    "distance_matrix = 1 - np.abs(correlation_matrix)\n",
    "dist_array = squareform(distance_matrix)\n",
    "dist_linkage = hierarchy.linkage(dist_array, method='ward')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 16))\n",
    "dendro = hierarchy.dendrogram(dist_linkage, labels=correlation_matrix.columns, ax=ax)\n",
    "ax.set_xticklabels(dendro[\"ivl\"], rotation=60, fontsize=4, horizontalalignment='right')\n",
    "ax.axhline(y=0.5, color='r', linewidth=2, linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "cluster_ids = hierarchy.fcluster(dist_linkage, 0.5, criterion=\"distance\")\n",
    "feature_clus = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'ClusterID': cluster_ids\n",
    "})\n",
    "# feature_clus.to_csv(\"Stroke_feature_clusters.csv\", index=False)"
   ],
   "id": "932bbbe4468a3a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_feature = X_train.copy()\n",
    "df_group = y_train.copy()\n",
    "scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "params = {\n",
    "    'alpha': 1.5,\n",
    "    'lambda': 1.5,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.9,\n",
    "    'eval_metric':'auc',\n",
    "    'scale_pos_weight': scale_pos_weight\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "def calculate_auc_for_feature(RNA_feature, df_feature, df_group, cv, params):\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, test_idx in cv.split(df_feature, df_group):\n",
    "        X_train, X_test = df_feature.iloc[train_idx], df_feature.iloc[test_idx]\n",
    "        y_train, y_test = df_group.iloc[train_idx], df_group.iloc[test_idx]\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train[[RNA_feature]], y_train)\n",
    "\n",
    "    y_pred_prob = model.predict_proba(X_test[[RNA_feature]])[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    aucs.append(auc)\n",
    "    return np.mean(aucs)\n",
    "\n",
    "auc_scores = {}\n",
    "for RNA_feature in df_feature.columns:\n",
    "    auc_score = calculate_auc_for_feature(RNA_feature, df_feature, df_group, cv, params)\n",
    "    auc_scores[RNA_feature] = auc_score\n",
    "\n",
    "feature_auc = pd.DataFrame(list(auc_scores.items()), columns=['Feature', 'AUC'])\n",
    "# feature_auc.to_csv(\"RNA_auc_scores.csv\", index=False)\n",
    "feature_auc.head()"
   ],
   "id": "6d86dc1a2aab863e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_sel = pd.merge(feature_auc, feature_clus, how='left', on=\"Feature\")\n",
    "best_features = feature_sel.loc[feature_sel.groupby('ClusterID')['AUC'].idxmax()]\n",
    "# best_features.to_csv('RNA_best_features.csv', index=False)"
   ],
   "id": "1811d56b42bf8f60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selected = best_features[\"Feature\"].tolist()\n",
    "X_train2 = X_train[selected].copy()\n",
    "X_test2 = X_test[selected].copy()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\n",
    "    'alpha': [1.5],\n",
    "    'lambda': [1.5],\n",
    "    'colsample_bytree': [0.75],\n",
    "    'n_estimators': [400],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [3],\n",
    "    'subsample': [0.7],\n",
    "    'min_child_weight': [3],\n",
    "    'gamma': [0.9],\n",
    "    'scale_pos_weight': [scale_pos_weight]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        eval_metric='auc',\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train2, y_train)\n",
    "best_model = grid_search.best_estimator_"
   ],
   "id": "5ad92f2b023832a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "explainer = shap.TreeExplainer(best_model)\n",
    "batch_size = 100\n",
    "shap_values_list = []\n",
    "\n",
    "for i in range(0, len(X_test2), batch_size):\n",
    "    batch = X_test2.iloc[i:i+batch_size]\n",
    "    shap_values_batch = explainer.shap_values(batch)\n",
    "    if isinstance(shap_values_batch, list):\n",
    "        shap_values_batch = shap_values_batch[1]\n",
    "    shap_values_list.append(shap_values_batch)\n",
    "    print(f\"Processed batch {i//batch_size + 1}/{(len(X_test2)//batch_size)+1}\")\n",
    "\n",
    "shap_values = np.concatenate(shap_values_list)\n",
    "# pd.DataFrame(shap_values, columns=X_test2.columns).to_csv('allrna_xgboost_shap_values.csv', index=False)\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test2, max_display=20, show=False)\n",
    "plt.show()"
   ],
   "id": "85919e0b6c036835",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fe0593a2e0f41c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'alpha': 1.5,\n",
    "    'lambda': 1.5,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.9,\n",
    "    'eval_metric':'auc',\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def normal_imp(mydict):\n",
    "    mysum = sum(mydict.values())\n",
    "    for key in mydict.keys():\n",
    "        mydict[key] = mydict[key] / mysum\n",
    "    return mydict\n",
    "\n",
    "tg_imp_cv = Counter()\n",
    "shap_imp_cv = np.zeros(X_train2.shape[1])\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_train2, df_group):\n",
    "    X_train, X_test = X_train2.iloc[train_idx, :], X_train2.iloc[test_idx, :]\n",
    "    y_train, y_test = df_group.iloc[train_idx], df_group.iloc[test_idx]\n",
    "\n",
    "    my_xgb = XGBClassifier(**params)\n",
    "    my_xgb.fit(X_train, y_train)\n",
    "\n",
    "    totalgain_imp = my_xgb.feature_importances_\n",
    "    totalgain_imp = dict(zip(X_train2.columns, totalgain_imp.tolist()))\n",
    "\n",
    "    tg_imp_cv += Counter(normal_imp(totalgain_imp))\n",
    "\n",
    "    explainer = shap.TreeExplainer(my_xgb)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    shap_values_mean = np.mean(np.abs(shap_values), axis=0)\n",
    "    shap_imp_cv += shap_values_mean / np.sum(shap_values_mean)"
   ],
   "id": "c0abc34d8012fd11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shap_imp_df = pd.DataFrame({\n",
    "    'Analytes': X_train2.columns,\n",
    "    'ShapValues_cv': shap_imp_cv / 10\n",
    "})\n",
    "shap_imp_df.sort_values(by='ShapValues_cv', ascending=False, inplace=True)\n",
    "\n",
    "stats_summary = {\n",
    "    'Mean': shap_imp_df['ShapValues_cv'].mean(),\n",
    "    'Std': shap_imp_df['ShapValues_cv'].std(),\n",
    "    'Min': shap_imp_df['ShapValues_cv'].min(),\n",
    "    'Max': shap_imp_df['ShapValues_cv'].max(),\n",
    "    '25%': shap_imp_df['ShapValues_cv'].quantile(0.25),\n",
    "    '50% (Median)': shap_imp_df['ShapValues_cv'].median(),\n",
    "    '75%': shap_imp_df['ShapValues_cv'].quantile(0.75)\n",
    "}\n",
    "\n",
    "print(\"SHAP Values CV Statistics:\")\n",
    "for stat, value in stats_summary.items():\n",
    "    print(f\"{stat}: {value:.4f}\")"
   ],
   "id": "dc18f3ed5a095699",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tg_imp_cv = normal_imp(tg_imp_cv)\n",
    "tg_imp_df = pd.DataFrame({\n",
    "    'Analytes': list(tg_imp_cv.keys()),\n",
    "    'TotalGain_cv': list(tg_imp_cv.values())\n",
    "})\n",
    "tg_imp_df"
   ],
   "id": "a84a4f457635f890",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "my_imp_df = pd.merge(left=shap_imp_df, right=tg_imp_df, how='left', on=['Analytes'])\n",
    "my_imp_df['Ensemble_cv'] = (my_imp_df['ShapValues_cv'] + my_imp_df['TotalGain_cv']) / 2\n",
    "my_imp_df.sort_values(by='TotalGain_cv', ascending=False, inplace=True)\n",
    "print('finished')"
   ],
   "id": "f3bbbc5dc94355cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_imp_analy(my_imp_df, top_prop=0.9):\n",
    "    imp_score, iter = 0, 0\n",
    "    while imp_score < top_prop and iter < len(my_imp_df):\n",
    "        imp_score += my_imp_df.Ensemble_cv.iloc[iter]\n",
    "        iter += 1\n",
    "    return iter\n",
    "\n",
    "top_feature_count = get_imp_analy(my_imp_df, top_prop=0.9)\n",
    "\n",
    "print(f\"Number of proteins contributing to over 90% of overall information gains: {top_feature_count}\")\n",
    "\n",
    "top_features_df = my_imp_df.iloc[:top_feature_count]\n",
    "# top_features_df.to_csv('Top_InfoGain_features.csv', index=False)\n",
    "# print('Top-ranked proteins saved to CSV.')"
   ],
   "id": "7aee48c2aa0b018d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_features = top_features_df['Analytes'].tolist()\n",
    "X_train3 = X_train[top_features]\n",
    "X_test3 = X_test[top_features]"
   ],
   "id": "df0de538fbb7a15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# AUC comparison adapted from\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5 * (i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=float)\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=float)\n",
    "    ty = np.empty([k, n], dtype=float)\n",
    "    tz = np.empty([k, m + n], dtype=float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, covar):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       covar: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, covar), l.T))  # 将 sigma 改为 covar\n",
    "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    return order, label_1_count\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    return calc_pvalue(aucs, delongcov)\n",
    "\n",
    "params = {\n",
    "    'alpha': 1.5,\n",
    "    'lambda': 1.5,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.9,\n",
    "    'eval_metric':'auc',\n",
    "    'scale_pos_weight': scale_pos_weight\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "y_pred_lst_prev1 = np.zeros(len(df_group))\n",
    "y_pred_lst_prev2 = np.zeros(len(df_group))\n",
    "y_pred_lst_prev3 = np.zeros(len(df_group))\n",
    "tmp_f, AUC_cv_lst = [], []\n",
    "\n",
    "for f in top_features:\n",
    "    tmp_f.append(f)\n",
    "    my_X = X_train3[tmp_f]\n",
    "\n",
    "    AUC_cv, y_pred_lst, y_true_lst = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in cv.split(my_X, df_group):\n",
    "        X_train, X_test = my_X.iloc[train_idx, :], my_X.iloc[test_idx, :]\n",
    "        y_train, y_test = df_group.iloc[train_idx], df_group.iloc[test_idx]\n",
    "\n",
    "        my_xgb = xgb.XGBClassifier(**params)\n",
    "        my_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_prob = my_xgb.predict_proba(X_test)[:, 1]\n",
    "        AUC_cv.append(roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "        y_pred_lst += y_pred_prob.tolist()\n",
    "        y_true_lst += y_test.tolist()\n",
    "\n",
    "    auc_full = roc_auc_score(y_true_lst, y_pred_lst)\n",
    "\n",
    "    log10_p1 = delong_roc_test(np.array(y_true_lst), np.array(y_pred_lst_prev1), np.array(y_pred_lst))\n",
    "    log10_p2 = delong_roc_test(np.array(y_true_lst), np.array(y_pred_lst_prev2), np.array(y_pred_lst))\n",
    "    log10_p3 = delong_roc_test(np.array(y_true_lst), np.array(y_pred_lst_prev3), np.array(y_pred_lst))\n",
    "\n",
    "    print(f\"Feature: {f}, Delong p-values: {log10_p1}, {log10_p2}, {log10_p3}\")\n",
    "\n",
    "    y_pred_lst_prev3 = y_pred_lst_prev2\n",
    "    y_pred_lst_prev2 = y_pred_lst_prev1\n",
    "    y_pred_lst_prev1 = y_pred_lst\n",
    "\n",
    "\n",
    "    tmp_out = np.array([np.mean(AUC_cv), np.std(AUC_cv), 10**log10_p1[0][0], 10**log10_p2[0][0], 10**log10_p3[0][0], auc_full])\n",
    "    AUC_cv_lst.append(tmp_out)\n",
    "    print(f\"Feature: {f}, AUC Results: {tmp_out}\")"
   ],
   "id": "371fb92724bc2be7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tmp_out = np.array([\n",
    "    np.mean(AUC_cv),\n",
    "    np.std(AUC_cv),\n",
    "    10**log10_p1[0][0],\n",
    "    10**log10_p2[0][0],\n",
    "    10**log10_p3[0][0],\n",
    "    auc_full\n",
    "])\n",
    "print(f\"Feature: {f}, AUC Results: {tmp_out}\")\n",
    "\n",
    "AUC_df = pd.DataFrame(AUC_cv_lst, columns=['AUC_mean', 'AUC_std', 'Delong1', 'Delong2', 'Delong3', 'AUC_all'])\n",
    "AUC_df[['AUC_mean', 'AUC_std', 'AUC_all']] = np.round(AUC_df[['AUC_mean', 'AUC_std', 'AUC_all']], 3)\n",
    "\n",
    "AUC_df = pd.concat((pd.DataFrame({'Analytes': tmp_f}), AUC_df), axis=1)\n",
    "AUC_df.to_csv('Delong_Selection_Results.csv', index=False)\n",
    "print('Finished feature selection and saved results.')"
   ],
   "id": "a8532f90502965fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_features_df.rename(columns = {'Ensemble_cv': 'sRNA_imp'}, inplace = True)\n",
    "mydf = pd.merge(AUC_df, top_features_df, how = 'left', on = ['Analytes'])\n",
    "mydf"
   ],
   "id": "8cc0844272b1e478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_nb_f(mydf):\n",
    "    p_lst = mydf.Delong2.tolist()\n",
    "    i = 0\n",
    "    while((p_lst[i]<0.05)|(p_lst[i+1]<0.05)):\n",
    "        i+=1\n",
    "    return i\n",
    "\n",
    "mydf['AUC_lower'] = mydf['AUC_mean'] - mydf['AUC_std']\n",
    "mydf['AUC_upper'] = mydf['AUC_mean'] + mydf['AUC_std']\n",
    "mydf['AUC_upper'].iloc[mydf['AUC_upper']>=1] = 1\n",
    "mydf['rna_idx'] = [i for i in range(1, len(mydf)+1)]\n",
    "nb_f = get_nb_f(mydf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (18, 6.5))\n",
    "palette = sns.color_palette(\"Blues\",n_colors=len(mydf))\n",
    "palette.reverse()\n",
    "sns.barplot(ax=ax, x = \"Analytes\", y = \"sRNA_imp\", palette=palette, data=mydf.sort_values(by=\"sRNA_imp\", ascending=False))\n",
    "y_imp_up_lim = round(mydf['sRNA_imp'].max() + 0.01, 2)\n",
    "ax.set_ylim([0, y_imp_up_lim])\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_xticklabels(mydf['Analytes'], rotation=45, fontsize=10, horizontalalignment='right')\n",
    "my_col = ['r']*nb_f + ['k']*(len(mydf)-nb_f)\n",
    "for ticklabel, tickcolor in zip(plt.gca().get_xticklabels(), my_col):\n",
    "    ticklabel.set_color(tickcolor)\n",
    "\n",
    "ax.set_ylabel('sRNA importance', weight='bold', fontsize=18)\n",
    "ax.set_xlabel('')\n",
    "ax.grid(which='minor', alpha=0.2, linestyle=':')\n",
    "ax.grid(which='major', alpha=0.5,  linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(np.arange(nb_f+1), mydf['AUC_mean'][:nb_f+1], 'red', alpha = 0.8, marker='o')\n",
    "ax2.plot(np.arange(nb_f+1, len(mydf)), mydf['AUC_mean'][nb_f+1:], 'black', alpha = 0.8, marker='o')\n",
    "ax2.plot([nb_f, nb_f+1], mydf['AUC_mean'][nb_f:nb_f+2], 'black', alpha = 0.8, marker='o')\n",
    "plt.fill_between(mydf['rna_idx']-1, mydf['AUC_lower'], mydf['AUC_upper'], color = 'tomato', alpha = 0.2)\n",
    "ax2.set_ylabel('Cumulative AUC', weight='bold', fontsize=18)\n",
    "ax2.tick_params(axis='y', labelsize=14)\n",
    "y_auc_up_lim = round(mydf['AUC_upper'].max() + 0.01, 2)\n",
    "y_auc_low_lim = round(mydf['AUC_lower'].min() - 0.01, 2)\n",
    "ax2.set_ylim([y_auc_low_lim, y_auc_up_lim])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim([-.6, len(mydf)-.2])\n",
    "plt.show()"
   ],
   "id": "c7e54715d3c31d03",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
